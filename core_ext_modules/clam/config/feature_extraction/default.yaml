# Configuration file for extracting features using the CLAM framework.

# Path settings
data_h5_dir : /run/media/iulta54/Expansion/Datasets/BTB/SCRIPTS/pre_processing/outputs/clam/BTB_patch_extraction_x20_256/2024-04-22 # path to the folder containing the .h5 patch coordinate files.
data_slide_dir : /run/media/iulta54/Expansion/Datasets/BTB/SCRIPTS/pre_processing/outputs/BTB_csv_2_hs2p_with_normals/2024-04-17/BTB_for_hs2p.csv # path to where the slides are located or a .csv file with the file paths. 
                 # If a .csv file is provided the slide_path column and the slide_id column should be present.
feat_dir :  /local/data2/iulta54/Data/BTB/histology_features/clam_features_mag_x20_size_256 # path to where the features should be saved
csv_path : /run/media/iulta54/Expansion/Datasets/BTB/SCRIPTS/pre_processing/outputs/BTB_csv_2_hs2p_with_normals/2024-04-17/BTB_for_hs2p.csv # path to the dataset_descriptor.csv file. This has three columns: case_id, slide:id, label

# experiment_name : BTB_CLAM_vit_conch_features_mag_x20_size_224
experiment_name : ${model_type}

# resume if feature extraction stopped
resume : false
auto_skip : True # Set to True to skip processing a slide if feature files are already available
stopped_experiment_dir :  # path to the stopped experiment 

# other settings
slide_ext : '.ndpi' # slide file extension
skip_missing_h5_patches : True # if to skip over a missing .h5 file if flagged by the .csv file for feature extraction
target_patch_size : -1
custom_downsample : 1
batch_size : 512

# feature extraction settings
model_type : resnet50 # here we can select between resnet50, vit_hipt, vit_uni. If the ViT models are used, specify the folder where the pre-trained models are stored.
pre_trained_model_archive : /local/data1/iulta54/Code/BTB_DEEP_LEARNING/pre_trained_feature_extractors

